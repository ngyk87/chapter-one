[
["index.html", "Chapter One - A Journey with DataKind SG Welcome Goals", " Chapter One - A Journey with DataKind SG DataKind SG 2018-03-23 Welcome Welcome to a new chapter in your journey with us at DataKind-SG! As with all great stories, we start with chapter one… At DataKind Singapore, we have worked with several Social Sector Partners to deliver data projects that aim to derive insights from their data and produce analyses and data products. We have since organized multiple Meetups to work on these data projects. This is a book on the lessons learnt and best practices derived from these data projects on executing large collaborative data projects. NOTE: This book is still in Alpha with many sections to be fleshed out. We seek your understanding should you encounter these sections. Nevertheless we still hope you have learnt a few tips from here. Goals Understand NGO’s requirements fully and translate requirements into clear specific tasks Quick view and easy management of project progress Facilitate sharing and mass collaboration Reproducible pipeline, from environment to code, data analyses, documentation and products Requirements traceability Meant to be a guide rather than a dogmatic approach for future DataKind Data Ambassadorss, Project Managers and Data Experts as well as anyone involved in data projects "],
["overview-of-project-flow.html", "Chapter 1 Overview of Project Flow 1.1 Project Funnel 1.2 Project Accelerators 1.3 DataJams 1.4 DataDive 1.5 DataCorps 1.6 DataLearn", " Chapter 1 Overview of Project Flow We shall have an overview of the overall data project flow in this chapter. This helps to set the context and helps you relate to the recommended practices described in this book. Subsequently we shall be taking a deep dive into the specific topics. While each of these chapters can be read independently depending on your needs, it references the project flow heavily and it helps if you read this chapter first. 1.1 Project Funnel In the picture below, you will see the project funnel that DataKind SG uses to assist our social sector partners DataKind Project Funnel 1.2 Project Accelerators This is the session where we bring the data science community together with our social sector partners in brainstorming sessions to take the first steps towards a successful data science project. 1.3 DataJams Once data has been obtained, we hold DataJam sessions that bring the data experts together with social sector partners to clean up and prepare the data prior to DataDives and/or DataCorps 1.4 DataDive DataDives are where the data experts and social sector partners collaborate to generate data solutions and/or products, tackling tough problems over the course of a weekend. 1.5 DataCorps DataCorps are specialized teams of pro bono data scientists who work on indepth, 6 to 9-month projects for social sector partners. 1.6 DataLearn From time-to-time, we may also conduct DataLearn sessions, where we help prepare our volunteers for DataDives through hands-on tutorials and workshops. "],
["project-management.html", "Chapter 2 Project Management 2.1 Tracking Progress 2.2 Tasks and Assignment 2.3 Recommended Roles 2.4 Tips", " Chapter 2 Project Management 2.1 Tracking Progress We use Trello for tracking progress. 2.2 Tasks and Assignment 2.3 Recommended Roles 2.4 Tips "],
["data-cleaning.html", "Chapter 3 Data Cleaning 3.1 Test Driven Data Cleaning", " Chapter 3 Data Cleaning 3.1 Test Driven Data Cleaning 3.1.1 For Volunteers Test Driven Data Cleaning is an approach that incorporates principles of Test Driven Development to achieve collaborative and reproducible data cleaning. Basically, data cleaning scripts are divided into test scripts and cleaning scripts. Test scripts document the expected outcomes from the data cleaning, hence we should aim to create the tests first before cleaning. Within each file you will see functions corresponding to the columns in the dataset pre-populated for you. The file names of test scripts are in the format test_clean_&lt;file name of dataset&gt;. Cleaning scripts are where you write code to the dataset. Similar to the test scripts, within cleaning script file, you will also see functions corresponding to the columns in the dataset pre-populated for you. On execution, the cleaning script will iterate through each column row-by-row to clean the dataset. The file names of cleaning scripts are in the format clean_&lt;file name of dataset&gt;. 3.1.1.1 Cloning the repository For version control, we are using Github. To clone (or get a copy of) the repository, run $ git clone &lt;path to Github repository&gt; 3.1.1.2 Assigning yourself a column To track progress, we use Trello boards. There will be a dedicated Trello board for each dataset file. Within the Trello board, you will be able to see a list of backlogs, where each Trello card corresponds to the name of a column, as shown in the below image. If you open each card, you will be able to see summary statistics that can be useful for writing methods to clean the column. Cleaning Backlog To start working on, say, column 1, add yourself to the corresponding Trello card. Subsequently, proceed to create a git branch by entering the following command. Creating the git branch allows you to make changes in isolation without affecting the master code base. We recommend the branch name to be in the form of test_clean_col_&lt;number&gt;. $ git checkout -b test_clean_col_1 3.1.1.3 Testing and cleaning a column for Python users In the test_clean_&lt;file name of dataset&gt;.py file, modify the test method as necessary. An example of the test method is shown below. @pytest.mark.skip def test_clean_col_1(): &quot;&quot;&quot; Test the cleaning for column: &quot;date&quot; &quot;&quot;&quot; assert clean_sample_data.clean_col_1(&#39;NA&#39;) == &#39;NA&#39; assert False By default, the test for column 1 is skipped. To enable the test, you will have to comment or remove the line @pytest.mark.skip as well as the line assert False. Subsequently, you can proceed to define the test(s) by using the assert statement. To test, run $ pytest test_clean_&lt;file name of dataset&gt;.py You will see the test results similar to the below: ============================= test session starts ============================== platform linux -- Python 3.6.2, pytest-3.2.1, py-1.4.34, pluggy-0.4.0 rootdir: /path/to/directory, inifile: collected 3 items test_clean_sample_data.py s.F =================================== FAILURES =================================== _______________________________ test_clean_col_2 _______________________________ def test_clean_col_2(): &quot;&quot;&quot; Test the cleaning for column: &quot;country&quot; &quot;&quot;&quot; &gt; assert clean_sample_data.clean_col_2(&#39;&#39;) == &#39;NA&#39; # expects test to fail E AssertionError: assert &#39;some wrong value&#39; == &#39;NA&#39; E - some wrong value E + NA test_clean_sample_data.py:28: AssertionError ================ 1 failed, 1 passed, 1 skipped in 0.03 seconds ================= In this example, you will see that there is 1 test function for each test outcome (failed, passed or skipped). You can also see a short version of the results in the line test_clean_sample_data.py s.F where ‘s’ means ‘skipped’, ‘.’ means ‘passed’, and ‘F’ means ‘failed’. You will also see which test has failed and its actual and expected output. Please note that you may have to install the pytest package to ensure the above command can be executed. To install pytest you can do so with one of the following commands: $ pip3 install pytest # install with pip (Python 3) $ conda install pytest # OR install with conda To generate the cleaned dataset, run $ python clean_&lt;file name of dataset&gt;.py You can find the generated file that is named cleaned_&lt;file name of dataset&gt;.csv in the designated directory. You can download and run the completed example test and cleaning scripts in the links below. test_clean_sample_data.py clean_sample_data.py sample_data.csv 3.1.1.4 Commit changes and create pull requests Run the following command to push your changes to Github. $ git add . $ git commit -m &quot;&lt;brief description of changes&gt;&quot; $ git push origin test_clean_col_1 Subsequently, login to Github and submit a pull request for the branch that you have just changed. Reference here. 3.1.2 For Team Leads 3.1.2.1 Pre-requisites You will need to have a Trello account. You can sign up for one at https://trello.com You will also need to install the tddc package. To get the latest version from Github, run the following: $ pip3 install git+https://github.com/DataKind-SG/test-driven-data-cleaning.git Last but not least, your dataset needs to be in CSV format. 3.1.2.2 Creating the scaffolds and Trello board In this walkthrough we shall use an example CSV file that can be downloaded from the link below. sample_data.csv In the same directory as the file, run: $ tddc summarize sample_data.csv This takes the csv data set and summarizes it, outputing to a json file in a newly created output/ directory. If this is the first time you’re running this, you should create a Trello configuration file named .tddc_config.yml in your user root directory with the format: trello: api_key: &lt;TRELL_API_KEY&gt; token: &lt;TRELLO_TOKEN&gt; You can get your Trello API key here: https://trello.com/app-key Replace your Trello API key at the end of this URL to get your Trello token (set to expire in 1 day): https://trello.com/1/authorize?expiration=1day&amp;scope=read,write,account&amp;response_type=token&amp;name=Server%20Token&amp;key=&lt;TRELLO_API_KEY&gt; Next, you can run: $ tddc build_trello sample_data.csv If .tddc_config.yml has not yet been created, the command will fail and give you instructions on how to create a Trello configuration file in your root directory. Once you create it, you can try to run that step again. This will create a Trello board named ‘Data Cleaning board for: ’ under the ‘Personal Boards’ section. You can then optionally move the board to your team in Trello via Show Menu &gt; More &gt; Settings &gt; Change Team... Next, you can run: $ tddc build sample_data.csv This outputs a script into the output/ folder that contains method stubs and glue code to clean the data set. It also outputs stubs for tests in output/. Please refer to the previous section for volunteers to see how these test and cleaning scripts can be used. Finally, commit the test and cleaning scripts to your team’s Github repository. "],
["managing-code.html", "Chapter 4 Managing Code 4.1 Version Control 4.2 Github FAQs 4.3 Directory Structure 4.4 Code Style 4.5 Preamble information to be placed at the top of every script 4.6 Quickstart Templates 4.7 Tips", " Chapter 4 Managing Code 4.1 Version Control Version Control is important to track changes made and to enable collaboration with other volunteers during the project. For this, we shall be using Github. Please refer to the below sections for the most common questions our volunteers have on Github usage. 4.2 Github FAQs 4.2.1 The csv.gz files seems to be too small/corrupted, what should I do? You will need to install Git LFS. Instructions can be found in the link below: https://help.github.com/articles/installing-git-large-file-storage/ 4.2.2 I’m new to Git, where can I get more information? You can refer to the the resources section of this documentation. 4.2.3 How to clone a git repository? Go to the command line and type the following git clone https://github.com/DataKind-SG/&lt;project_name&gt;.git OR if you are using git large file storage: git-lfs clone https://github.com/DataKind-SG/&lt;project_name&gt;.git 4.2.4 How to load csv.gz files? If you are using R: read.csv(gzfile(&quot;filename.csv.gz&quot;)) OR library(readr) read_csv(&quot;filename.csv.gz&quot;) If you are using Python: import pandas as pd pd.read_csv(&#39;filename.csv.gz&#39;) 4.2.5 How can I safely edit the code and data files? We recommend that you first create a “branch” in git - think of it as a personal copy - and make your changes. Then you submit a “pull request” for review - think of it as a notification for the admins to review and update the main files 4.2.6 Doing a git branch We recommend to name your branches in the following format: “-” git checkout -b &quot;name of the branch&quot; 4.2.7 How to submit changes to the code repository git add . git commit -m &quot;brief description of change&quot; git push origin &lt;branch name&gt;&quot; To do a pull request, please refer to this link: https://help.github.com/articles/creating-a-pull-request/ 4.3 Directory Structure ├── _scripts | ├── subtask1 | ├── subtask2 ├── _data | ├── subdata1 | ├── subdata2 |--- _outputs 4.4 Code Style 4 spaces, not tabs 4.5 Preamble information to be placed at the top of every script Intent/Purpose What’s the purpose of the script Input Param/external data that the script needs Output What it produces Dependencies Libraries/setup that the script needs in order to run Sample Usage Sample demo on how to run/call the script You can view a sample Script here. To add the files into Docker, you need to additional environment information (quay.io docker filepath) e.g., for R: #‘docker_filepath: quay.io/dksg/children-society-r-notebook:x.x.x) - Author: e.g., for R: #’ author:Paul - Summary of the objective of script. e.g., #’ desc: takes in the file_1, file_2 and file_3, performs xxx, yyy, and zzz, and produces output_1 and output_2 4.6 Quickstart Templates dksg_template.R 4.7 Tips "],
["docker-pipeline-for-reproducible-research.html", "Chapter 5 Docker Pipeline for Reproducible Research 5.1 Overview 5.2 Prerequisites 5.3 Task 1: Setup Dockerfile 5.4 Task 2: Setup CI and Build Docker Image 5.5 Task 3: Curate Deliverables 5.6 Task 4: Resolve Environment Issue", " Chapter 5 Docker Pipeline for Reproducible Research Workshop version: 1.0.0 Last updated: 2018-03-23 TinyUrl Links: https://tinyurl.com/fossasia https://tinyurl.com/dockerlab 5.1 Overview Datakind Singapore has been using docker to help reproduce environments that were used during DataDive events. Apart from versioning the files/scripts that were used during analysis, we also version the environments where we ran such scripts. In this workshop, we’ll walkthrough how we use docker to promote reproducibility. 5.2 Prerequisites In order to follow along in this workshop, you would need to have an account in github, quay.io, and play-with-docker. If you don’t have yet, kindly create an account in the following platforms: https://github.com https://quay.io https://labs.play-with-docker.com/ 5.3 Task 1: Setup Dockerfile Before a DataDive event, we try to engage with the NGO team representatives to know what data tools the volunteers will be using during the event. Based on previous DataDive events, RStudio and Jupyter Notebooks tend to be popular among volunteers. In this workshop, we’ll try to build a docker image for a python jupyter notebook. To save time, we already prepared a dockerfile and related demo materials for you. Login to your github using your account. Then, kindly fork the following repository to your github account: https://github.com/DataKind-SG/contain-yourself Once fork is done, “contain-yourself” repo should now be reflected in your github account. Open and examine your dockerfile: https://github.com/&lt;github_account&gt;/contain-yourself/tree/master/workshop/demo_docker_setup/Dockerfile Replace &lt;github_account&gt; with your github account e.g. https://github.com/therealdatascientist/contain-yourself/tree/master/workshop/demo_docker_setup/Dockerfile In this dockerfile, we’re using the jupyter/minimal-notebook base image. This contains the corresponding OS and minimal python installation to support jupyter notebook. We also reference the version of the base image, so that we won’t be affected in case the version of the base image increments. This is so that we can still reproduce that actual base image used when the data analysis was done. We also keep track of the python package versions that will later be used when building our jupyter image. You can find the list inside the requirements file: https://github.com/&lt;github_account&gt;/contain-yourself/tree/master/workshop/demo_docker_setup/requirements.txt Now that our dockerfile is ready, we can proceed in syncing github to a continuous integration (CI) process. 5.4 Task 2: Setup CI and Build Docker Image Login to your quay.io account and go to the repository homepage: https://quay.io/repository/ Create a new repository Set it up as follows: Click “Create Public Repository” Authorize coreos Select the organization under which the repository lives. In this workshop, use your github account. Then, click continue. Select the contain-yourself repository under your github account. Then, click continue. Configure the trigger so that it will only build the container image if there’s a new change in the master branch. Then, click continue. Select the Dockerfile under workshop: /workshop/demo_docker_setup/Dockerfile Then, click continue. Select the context where our dockerfile is located: /workshop/demo_docker_setup Then, click continue. There’s no need for a Robot Account as we’re using a public base image. Just click continue. Whew! We’re ready to go. Click continue. Click the link to return to your repository page Initiate a new build by clicking “Start New Build” button Click “Run Trigger Now” Select master branch. Then, click “Start Build” button. You should see the flashing dots indicating that the build has started. Once the build is complete , click the label section . Click the setting button on the latest tag and click “Add New Tag” Enter the version as the tag name. We use semantic versioning (https://semver.org/) MAJOR.MINOR.PATCH Enter 1.0.0 Then, click “Create Tag” button You should now see a new tag (version) displayed. This is how we version our environments to promote reproducibility later. Now that we have a versioned notebook image (environment), You can proceed in curating our volunteers’ deliverables and confirm if you can reproduce their analysis. 5.5 Task 3: Curate Deliverables Trivia: In the previous DataDive, we have a dedicated team of deliverable curators. We call them our Docker Captains. They help confirm and ensure that our volunteers’ analysis/outputs are reproducible. In this task, we’ll put on our Docker Captain hat and curate some jupyter notebooks. Docker captains usually have docker installed in their laptops during the DataDive and use that for curation. However in this workshop, we’ll use play-with-docker so that you don’t need to setup docker locally in your machine. Login to Play with Docker: https://labs.play-with-docker.com/ Click Start Click ADD NEW INSTANCE In the console, git clone your contain-yourself github repo. Type the following: git clone https://github.com/&lt;your github account&gt;/contain-yourself.git Then, hit enter. Type the following: docker run -p 80:8888 -v /root/contain-yourself/workshop/demo_notebooks:/home/jovyan/work quay.io/&lt;your quay.io account name&gt;/workshop-notebook:1.0.0 Then, hit enter. It will start pulling the image from quay.io. Once your jupyter token is ready, click on the port 80 link In the previous step, we had mapped our container’s port 8888 to the host’s port 80. A new tab will open for jupyter. Enter your jupyter token accordingly and click Log in. You should now see 2 notebooks and 1 json data file. Click the notebook of volunteer 1: analysis_from_volunteer_1.ipynb In volunteer 1’s notebook, click Cell. Then, click Run All. Scroll to the bottom of the notebook. You should see the following stacked bar chart generated: Woohoo! We just successfully reproduced Volunteer 1’s analysis. Note: Ideally, the docker captain will now proceed to add meta data on this notebook to indicate which version of the environment was used to run this successfully. However, we’ll skip that in this workshop. Close the browser tab of volunteer 1’s notebook. Click the notebook of volunteer 2: analysis_from_volunteer_2.ipynb In volunteer 2’s notebook, click Cell. Then, click Run All. In the 3rd code cell, you should see this: Oh no! We don’t have bokeh in the current jupyter environment version. We can’t reproduce Volunteer 2’s analysis. O Captain! my Captain! Don’t be downcast Your will is strong and the 4th task is your last 5.6 Task 4: Resolve Environment Issue Note: We’re fortunate that this issue is pretty straightforward to fix. We’re just missing a package (bokeh). In other scenarios, docker captains face more complex issues than this (e.g. version incompatibility, missing OS binaries, etc.). It’s always helpful when the author of the deliverable is still around so that such issues can be resolved quicker. In this workshop, we kept it simple. Go back to your contain-yourself github repo and open requirements.txt: https://github.com/&lt;your github account&gt;/contain-yourself/blob/master/workshop/demo_docker_setup/requirements.txt Click Edit Write bokeh and its corresponding version (0.12.4) in the requirements.txt Scroll down. Add info. Then, commit changes. Go back to your build page in quay.io: https://quay.io/repository/&lt;your quay.io account&gt;/workshop-notebook?tab=builds Notice that quay.io automatically picked up our change and started building. Once the build is complete , click the label section . Click the setting button on the latest tag and click “Add New Tag” Note: Ensure that the latest is really the latest. Check the Last Modified stamp. If it’s not, try refreshing the page. Enter the version as the tag name. We use semantic versioning (https://semver.org/) MAJOR.MINOR.PATCH Enter 1.0.1 Then, click “Create Tag” button You should now see a new tag (version) displayed. Version 1.0.1 is the version of our jupyter image that has the bokeh package. Go back to your play-with-docker console. If the jupyter process is still running, kill it by hitting CTRL+C. That should shutdown the jupyter kernels accordingly. Type the following: docker run -p 80:8888 -v /root/contain-yourself/workshop/demo_notebooks:/home/jovyan/work quay.io/&lt;your quay.io account name&gt;/workshop-notebook:1.0.1 Then, hit enter It will start pulling the new image (version 1.0.1) from quay.io. Once your jupyter token is ready, click on the port 80 link A new tab will open for jupyter. Enter your jupyter token accordingly and click Log in. You should now see 2 notebooks and 1 json data file. Let’s open the notebook where we had issue previously. Click the notebook of volunteer 2: analysis_from_volunteer_2.ipynb In volunteer 2’s notebook, click Cell. Then, click Run All. Scroll to the bottom of the notebook. You should see the following stacked bar chart generated: Congratulations! You fixed the environment issue and you’re now able to successfully reproduce Volunteer 2’s analysis. You have the skill of a DataDive Docker Captain. Checkout DataKind Singapore meetup event for volunteering opportunities: https://www.meetup.com/DataKind-SG/events/ "],
["data-protection-and-information-ethics.html", "Chapter 6 Data Protection and Information Ethics 6.1 Data Protection 6.2 Information Ethics", " Chapter 6 Data Protection and Information Ethics We appeal to your common sense and sense of Responsibility here. 6.1 Data Protection Data Protection refers to the “control over access to and use of data stored in computers” As a volunteer, you are responsible to hold yourself to the highest standards of data collection, privacy and security. 6.2 Information Ethics Information Ethics refers to a “branch of ethics that focuses on the relationship between the creation, organization, dissemination, and use of information” As a volunteer, you are morally obliged to perform analysis that is ethically correct according to the guidelines set by your social sector partner. "],
["resources.html", "Chapter 7 Resources 7.1 Tools 7.2 Cheatsheets 7.3 Videos", " Chapter 7 Resources 7.1 Tools 7.1.1 Test Driven Data Cleaning Please refer to your respective project repository’s readme on how test driven data cleaning can be used. 7.1.1.1 Python users Github Repository 7.1.1.2 R users testthat on CRAN Getting started with testing 7.1.2 Github 7.1.2.1 Github Desktop and other IDEs Github Desktop User Guides Using version control with RStudio 7.1.2.2 Command Line git - the simple guide 7.1.3 Trello Trello Tutorial Getting Started with Trello (Video Demo) 7.2 Cheatsheets You can refer to the below links for cheatsheets that might be useful. 7.2.1 R Collection of RStudio Cheatsheets 7.2.2 Python Pandas Cheatsheet Python Cheatsheets 7.3 Videos DataLearn: Docker for Reproducible Research, presented by Paul, recorded by Engineers.SG "],
["about.html", "Chapter 8 About 8.1 About DKSG 8.2 Contributors", " Chapter 8 About 8.1 About DKSG About DataKind Singapore 8.2 Contributors "],
["references.html", "References", " References "]
]
